{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_comp_vision_cat_ 26_June.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adryduty/computer-vision-cat-project/blob/main/Training_comp_vision_cat__26_June.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = red> Training"
      ],
      "metadata": {
        "id": "TYfQLKdRXrfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue> Load all the needed modules"
      ],
      "metadata": {
        "id": "c0rxp5-eXWE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "XOJT9jU_XY_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **torch:** to load the trained model\n",
        "* **os:** to create folders\n",
        "* **shutil:** to move files from one folder to another\n",
        "* **random:** to split the dataset in training, validation and testing set"
      ],
      "metadata": {
        "id": "TOF-nq664vlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue> Load the YOLO with all the dependencies. This code will also tell you if you're using the GPU or not. Moreover it will tell you which GPU you are using."
      ],
      "metadata": {
        "id": "kZ88i7NNAmtv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mz4Ptmf-Ex8",
        "outputId": "c409edb4-c1ce-471b-8f04-764352df7ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12287, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 12287 (delta 1), reused 0 (delta 0), pack-reused 12281\u001b[K\n",
            "Receiving objects: 100% (12287/12287), 12.07 MiB | 28.42 MiB/s, done.\n",
            "Resolving deltas: 100% (8476/8476), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 596 kB 28.7 MB/s \n",
            "\u001b[?25hSetup complete. Using torch 1.11.0+cu113 (CPU)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue> **(1)** Load images and labels. **(2)** Create new folders (training, validation and testing set) and store the images and the labels properly. **(3)** Create the yaml file."
      ],
      "metadata": {
        "id": "3HOKDlUfbz7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load images and labels (notice that are in the same zip file that you have to load by yourself)"
      ],
      "metadata": {
        "id": "A53LDjhUAqFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This chunk allows to change the directory in the /content directory\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuBJ0UlT_Fyy",
        "outputId": "47fe0d64-1135-4b21-a6b0-539642ee58a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file = \"archive.zip\"\n",
        "\n",
        "if os.path.isfile(zip_file):\n",
        "  shutil.unpack_archive(zip_file, \"data\")\n",
        "else:\n",
        "  print(zip_file + \" not found\")"
      ],
      "metadata": {
        "id": "ull91s2z_23V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create new folders"
      ],
      "metadata": {
        "id": "EtXMgQ4xAtpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_tree = [\"/content/data/images/training\",\n",
        "            \"/content/data/images/validation\",\n",
        "             \"/content/data/images/testing\",\n",
        "             \"/content/data/labels/training\",\n",
        "             \"/content/data/labels/validation\",\n",
        "             \"/content/data/labels/testing\"]\n",
        "            \n",
        "for path in path_tree:\n",
        "  os.makedirs(path)"
      ],
      "metadata": {
        "id": "GZZCqNS-_HTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_labels_dict_creator(source):\n",
        "  '''\n",
        "  - Input: source path where are stored the images (jpg format) and the labels (txt format)\n",
        "\n",
        "  - Output: a tuple with a list of the names of all the pictures (without labels) and\n",
        "  a dictionary where the keys are the images and the values are the labels.\n",
        "  '''\n",
        "  images_list = [item for item in os.listdir(source) if item.endswith(\"jpg\")] # Images list\n",
        "  labels_list = [item for item in os.listdir(source) if item.endswith(\"txt\")] # labels list\n",
        "  images_list.sort()\n",
        "  labels_list.sort()\n",
        "  images_labels_dict = dict(zip(images_list, labels_list))\n",
        "  \n",
        "  return images_list, images_labels_dict"
      ],
      "metadata": {
        "id": "PXkkZbIKFA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_path_changer(source, dest): \n",
        "  '''\n",
        "  This function moves the files from the path 'source' to the path 'dest'\n",
        "  '''\n",
        "  shutil.move(source, dest)\n"
      ],
      "metadata": {
        "id": "wmpUXepqETCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk uses the functions we have created above.\n",
        "**Steps:** <br>\n",
        "* For reproducibility reasons we use a random seed.\n",
        "* Assign to source the path of archive and then use this path as input for the images_labels_dict_creator function. The output is assigned to images_list and images_labels_dict.\n",
        "* Set the size of the training set. In this case we choose $70$%.\n",
        "* Assign to training_set a random sample ($70$%) of the images. \n",
        "* For each image in the training set, move it in /content/data/images/training/ path.\n",
        "* images_labels_dict is a dictionary having as key the image names and as value the labels. So, take the label of the image you have already stored in /content/data/images/training/ and move it in the following path: /content/data/labels/training/ .\n",
        "* So far, we have stored the training set images and labels where they have to be, now, lets store the validation set images and labels.\n",
        "* As we did previously, we use the images_labels_dict_creator function with the source path to see which images are stored in this path (obviously, now there are $70$% less, because we moved them).\n",
        "* We choose the size of the validation set as $66$% of the remaining $30$% images: $66$% * $30$% = $20$%.\n",
        "* We assign to validation_set a random sample ($66$%) of the images in images_list.\n",
        "* We iterate through each image in validation_set and move the images in /content/data/images/validation/ and the corresponding labels in /content/data/labels/validation/ ."
      ],
      "metadata": {
        "id": "zo5N8st3yC-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "source = \"/content/data/archive/\"\n",
        "\n",
        "images_list, images_labels_dict = images_labels_dict_creator(source)\n",
        "\n",
        "training_set_dim = int(len(images_list)*0.7)\n",
        "\n",
        "training_set = random.sample(images_list, training_set_dim)\n",
        "\n",
        "for image_name in training_set: # random.sample doesn't take two times the same element in images_list (replace = False)\n",
        "  file_path_changer(source + image_name, \"/content/data/images/training/ \" + image_name) \n",
        "  label_name = images_labels_dict[image_name] \n",
        "  file_path_changer(source + label_name, \"/content/data/labels/training/ \" + label_name) \n",
        "\n",
        "\n",
        "images_list, images_labels_dict = images_labels_dict_creator(source)\n",
        "validation_set_dim = int(len(images_list)*0.66)\n",
        "\n",
        "validation_set = random.sample(images_list, validation_set_dim)\n",
        "\n",
        "for image_name in validation_set:\n",
        "  file_path_changer(source + image_name, \"/content/data/images/validation/ \" + image_name) \n",
        "  label_name = images_labels_dict[image_name] \n",
        "  file_path_changer(source + label_name, \"/content/data/labels/validation/ \" + label_name) "
      ],
      "metadata": {
        "id": "uE_MCajWBPzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk creates a yaml file and stores it in /content/yolov5/dataset.yaml"
      ],
      "metadata": {
        "id": "qT0X9sUNAyVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/yolov5/dataset.yaml\", \"w\")\n",
        "\n",
        "f.write(\"train: ../data/images/training/\\n\")\n",
        "f.write(\"val: ../data/images/validation/\\n\")\n",
        "f.write(\"nc: 1\\n\")\n",
        "f.write(\"names: ['GHIRI']\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "3JzDU_HjALUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue> Train the model"
      ],
      "metadata": {
        "id": "3_zNQIaAA0mM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk changes the directory in the one of yolov5 and computes the tuning of the hyperparameters according to a genetic algorithm (more information on the appendix). We can do that thanks to the evolve parameter.\n",
        "### Moreover we use resized images ($416*416$), a mini-batch size of 50, 150 epochs, the data indicated in the yaml file and the starting weights of the yolov5s.pt (in the documentation of yolov5 it's suggested to use these weights as starting weights instead of using random ones). The cache command is just for speeding up the computation."
      ],
      "metadata": {
        "id": "KHhgM4gp2oYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "!python train.py --img 416 --batch 50 --epochs 150 --data /content/yolov5/dataset.yaml --weights yolov5s.pt --cache --evolve 40"
      ],
      "metadata": {
        "id": "NfQ1Y-MKAcYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here we are going to train using the best hyperparameters that we found in the previous code."
      ],
      "metadata": {
        "id": "8Im5oAjdrrpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "!python train.py --img 416 --batch 50 --epochs 150 --data /content/yolov5/dataset.yaml --weights yolov5s.pt --cache --hyp /content/hyp_evolve.yaml"
      ],
      "metadata": {
        "id": "T-Q9HyRElY-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With the following chunk you can see the plots of the results"
      ],
      "metadata": {
        "id": "itnAqO2H4h0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "pBe71MmNKiY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue> Test the model"
      ],
      "metadata": {
        "id": "NPuPx4LzA1K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eventually, the following two cells allow us to see which are the results on images that the model has never seen (testing set)."
      ],
      "metadata": {
        "id": "E4ArK3Vu4yeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"/content/data/archive/\"\n",
        "\n",
        "images_list, images_labels_dict = images_labels_dict_creator(source)\n",
        "\n",
        "testing_set = images_list\n",
        "\n",
        "for image_name in testing_set: # random.sample doesn't take two times the same element in images_list (replace = False)\n",
        "  file_path_changer(source + image_name, \"/content/data/images/testing/ \" + image_name) \n",
        "  label_name = images_labels_dict[image_name] \n",
        "  file_path_changer(source + label_name, \"/content/data/labels/testing/ \" + label_name)  "
      ],
      "metadata": {
        "id": "rZMVr0nUD143"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "# Remember first to load the best.pt file in colab\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", 'custom', path=\"/content/best.pt\")\n",
        "#model = torch.hub.load(\"ultralytics/yolov5\", 'custom', path=\"/content/yolov5/runs/train/exp/weights/best.pt\")\n",
        "\n",
        "model.conf = 0.6\n",
        "\n",
        "# Images\n",
        "img = '/content/data/archive/img10.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
        "\n",
        "img_lists = os.listdir('/content/data/images/testing/')\n",
        "path_img_lists = ['/content/data/images/testing/'+img for img in img_lists]\n",
        "\n",
        "# Inference\n",
        "results = model(path_img_lists)\n",
        "\n",
        "# Results\n",
        "results.save()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "metadata": {
        "id": "X1jsjvybLDAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The following chunk allows you to use a video for testing the network"
      ],
      "metadata": {
        "id": "qhdp3HoZDZEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/bracciolo.mov --weights /content/best.pt"
      ],
      "metadata": {
        "id": "dDNSvuNg-23m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a font color = blue> APPENDIX\n",
        "\n",
        "Genetic algorithms (GAs) are stochastic search algorithms inspired by the basic principles of biological evolution and natural selection. GAs simulate the evolution of living organisms, where the fittest individuals dominate over the weaker ones, by mimicking the biological mechanisms of evolution, such as selection, crossover and mutation.\n",
        "\n",
        "We used a GA to determine the hyperparameters by selecting the best ones that can be obtained by a combination of ”individuals” (vectors) having certain “genes” (parameters)."
      ],
      "metadata": {
        "id": "lLhBrlD3vXLB"
      }
    }
  ]
}