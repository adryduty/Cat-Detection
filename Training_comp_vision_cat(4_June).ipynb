{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training comp_vision_cat(4 June).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFwsRrgdNsxuDYW/Tp4rbB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adryduty/computer-vision-cat-project/blob/main/Training_comp_vision_cat(4_June).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk allows you to create a yolov5 folder with all the things you need."
      ],
      "metadata": {
        "id": "qHoO8Xzhzvk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qAQo-kMtzkyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c66730-3fec-40d4-ff14-ac290a50096a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12173, done.\u001b[K\n",
            "remote: Total 12173 (delta 0), reused 0 (delta 0), pack-reused 12173\u001b[K\n",
            "Receiving objects: 100% (12173/12173), 11.90 MiB | 19.56 MiB/s, done.\n",
            "Resolving deltas: 100% (8429/8429), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 596 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 45.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 18.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 686 kB/s \n",
            "\u001b[?25h  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Setup complete. Using torch 1.11.0+cu113 (CPU)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import io\n",
        "import numpy as np    \n",
        "from PIL import Image\n",
        "import pickle\n",
        "from google.colab import files, drive\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as plticker\n",
        "import time\n",
        "import matplotlib.patches as patches\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from math import floor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "pZGTWa-pz7qB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreating all the directories of roboflow before applying the yolov5"
      ],
      "metadata": {
        "id": "iaMsrERR0FI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk creates empty folders"
      ],
      "metadata": {
        "id": "Sa3pueq20HUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/yolov5/Gatto-1\"\n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/yolov5/Gatto-1/test\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/validation\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/training\"\n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/yolov5/Gatto-1/test/images\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/validation/images\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/training/images\"\n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/yolov5/Gatto-1/test/labels\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/validation/labels\"\n",
        "os.mkdir(path)\n",
        "path = \"/content/yolov5/Gatto-1/training/labels\"\n",
        "os.mkdir(path)"
      ],
      "metadata": {
        "id": "2FL5EIcXz7n7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_path_changer(source, dest): \n",
        "  '''\n",
        "  This function moves the files from the path 'source' to the path 'dest'\n",
        "  '''\n",
        "  shutil.move(source, dest)\n"
      ],
      "metadata": {
        "id": "9sR0D5pRz7lm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/label_154.csv\")"
      ],
      "metadata": {
        "id": "6hSsvTfbz7jg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 42)\n",
        "\n",
        "validation, test = train_test_split(test, train_size = 0.66, test_size = 0.34, random_state = 42)\n",
        "\n",
        "train_labels = train.iloc[:, 1:].values\n",
        "valid_labels = validation.iloc[:, 1:].values\n",
        "test_labels = test.iloc[:, 1:].values\n",
        "\n",
        "train_im_list = list(train.iloc[:,0])\n",
        "valid_im_list = list(validation.iloc[:, 0])\n",
        "test_im_list = list(test.iloc[:, 0])"
      ],
      "metadata": {
        "id": "zMPIFEw_z7hK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk saves labels and image names in the proper folders (after having uploaded by hand)"
      ],
      "metadata": {
        "id": "yKXdXN9z0OyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(train_im_list)):\n",
        "  file_name = \"/content/yolov5/Gatto-1/training/labels/\" + list(train_im_list)[index].split(\"/\")[2].split(\".\")[0] + \".txt\"\n",
        "  f = open(file_name, \"w\")\n",
        "  f.write(str(train_labels[index])[1:-1])\n",
        "  f.close()\n",
        "\n",
        "\n",
        "for index in range(len(valid_im_list)):\n",
        "  file_name = \"/content/yolov5/Gatto-1/validation/labels/\" + list(train_im_list)[index].split(\"/\")[2].split(\".\")[0] + \".txt\"\n",
        "  f = open(file_name, \"w\")\n",
        "  f.write(str(train_labels[index])[1:-1])\n",
        "  f.close()\n",
        "\n",
        "\n",
        "for index in range(len(test_im_list)):\n",
        "  file_name = \"/content/yolov5/Gatto-1/test/labels/\" + list(train_im_list)[index].split(\"/\")[2].split(\".\")[0] + \".txt\"\n",
        "  f = open(file_name, \"w\")\n",
        "  f.write(str(train_labels[index])[1:-1])\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "u9OkIlGBz7fD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move the images from /content/imageName.jpg to the proper directory"
      ],
      "metadata": {
        "id": "qUsWW5bM0Syq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for source in train_im_list:\n",
        "  dest = \"/content/yolov5/Gatto-1/training/images\"\n",
        "  file_path_changer(source, dest)\n",
        "\n",
        "for source in valid_im_list:\n",
        "  dest = \"/content/yolov5/Gatto-1/validation/images\"\n",
        "  file_path_changer(source, dest)\n",
        "\n",
        "for source in test_im_list:\n",
        "  dest = \"/content/yolov5/Gatto-1/test/images\"\n",
        "  file_path_changer(source, dest)"
      ],
      "metadata": {
        "id": "NzRDmkgFz7cx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The following chunk is for the yaml"
      ],
      "metadata": {
        "id": "3bmGrwSr0Wbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=open(\"/content/yolov5/Gatto-1/data.yaml\", \"w\")\n",
        "data.write(\"names:\\n- Cat1\\nnc: 1\\ntrain: /content/yolov5/Gatto-1/training/images\\nval: /content/yolov5/Gatto-1/validation/images\\n\")\n",
        "data.close()"
      ],
      "metadata": {
        "id": "h22GeFpIz7MI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the YOLOv5 (we used a yolov5s)"
      ],
      "metadata": {
        "id": "UPuwesZX0Z5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 30 --epochs 300 --data /content/yolov5/Gatto-1/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "G626n5hd0XF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model (by using the best.pt weights you have just got)"
      ],
      "metadata": {
        "id": "9Sc_iF8S0dho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
        "                       path='/content/yolov5/runs/train/exp/weights/best.pt', force_reload=True)\n",
        "\n",
        "model.conf = 0.25\n",
        "model.iou = 0.45\n",
        "model.agnostic = False\n",
        "model.multi_label = False\n",
        "model.classes = None\n",
        "model.max_det = 1000\n",
        "model.amp = False\n",
        "\n",
        "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s') # This is pretrained (200000 pictures)"
      ],
      "metadata": {
        "id": "q0lgbpMF0XDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e397d48a-4d95-471d-f355-a968f493175d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2022-6-6 Python-3.7.13 torch-1.11.0+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir('/content/yolov5/Gatto-1/test/images'):\n",
        "  img = Image.open('/content/yolov5/Gatto-1/test/images/' + filename)\n",
        "  results = model(img)\n",
        "  results.save()"
      ],
      "metadata": {
        "id": "UdhP5emX0XBj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.xywhn) # x center, y center, width, height, probability, class (ALL SCALED TO 1)\n",
        "print(results.xywh) # x center, y center, width, height, probability, class (ALL NOT SCALED TO 1)"
      ],
      "metadata": {
        "id": "IC0av3IC0W_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ed22ed-d2a1-4bf7-c449-f35c9141f659"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0.60287, 0.26370, 0.31938, 0.32483, 0.87996, 0.00000]])]\n",
            "[tensor([[250.79568, 109.69796, 132.86078, 135.13115,   0.87996,   0.00000]])]\n",
            "torch.Size([1, 3, 640, 640])\n",
            "(8.924245834350586, 349.73740577697754, 0.8711814880371094)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B7l16NQm0W9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}